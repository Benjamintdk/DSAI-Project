{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a09324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-aberdeen",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering\n",
    "> Cleaning and feature engineering based on the insights gained from the previous step on EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e441aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a04936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# This only needs to be run once\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from pandas import DataFrame\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from DSAI_proj.extract import *\n",
    "from DSAI_proj.eda import *\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea105654",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-artwork",
   "metadata": {},
   "source": [
    "The first step will be to process the categorical variables of the dataset. In this case, we have genres as a categorical variable. We will use the MultiLabelBinarizer from scikit-learn to one-hot-encode the movie genres. This will create additional columns in our DataFrame, each corresponding to a separate genre type. We will reuse the clean_genre function used in the EDA section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>...</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/hQ4pYsIbP22TMXOUdSfC2mjWrO0.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/l94l89eMmFKh7na2a1u5q67VgNx.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>/u0zMKKpEdDWpOKmFW2sLbKKICJH.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>/5aXp2s4l6g5PcMMesIj63mx8hmJ.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  adult                     backdrop_path belongs_to_collection  \\\n",
       "0           0  False  /hQ4pYsIbP22TMXOUdSfC2mjWrO0.jpg                   NaN   \n",
       "1           1  False  /l94l89eMmFKh7na2a1u5q67VgNx.jpg                   NaN   \n",
       "2           2  False  /u0zMKKpEdDWpOKmFW2sLbKKICJH.jpg                   NaN   \n",
       "3           3  False  /5aXp2s4l6g5PcMMesIj63mx8hmJ.jpg                   NaN   \n",
       "4           4  False                               NaN                   NaN   \n",
       "\n",
       "   ...  TV Movie Thriller  War Western  \n",
       "0  ...         0        0    0       0  \n",
       "1  ...         0        0    0       0  \n",
       "2  ...         0        0    0       0  \n",
       "3  ...         0        1    0       0  \n",
       "4  ...         0        0    0       0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_genre(df=movies)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-bermuda",
   "metadata": {},
   "source": [
    "Next, we will need to extract the images into a separate directory. This will allow for easier access during the training stage. The following codes help us to extract the backdrop and poster images from their urls to separate directories. We can multithread this function as well as it involves multiple IO operations. Additionally, as some examples will not have images, we will drop these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def req_image(url: str, save_path: str, id_num: int):\n",
    "    req_url = f\"https://image.tmdb.org/t/p/original{url}\"\n",
    "    response = requests.get(req_url)\n",
    "    if response.status_code == 200:\n",
    "        fname = os.path.join(save_path, f\"{id_num}.jpg\")\n",
    "        with open(fname, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "            return None\n",
    "    return id_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def extract_images_threaded(df: DataFrame,\n",
    "                            cur_path: str,\n",
    "                            img_type: list,\n",
    "                            max_threads: int) -> tuple:\n",
    "    max_threads = max_threads if max_threads < len(df) else len(df)\n",
    "    problem_ids = []\n",
    "    for itype in img_type:\n",
    "        save_path = os.path.join(cur_path, f\"{itype}_img\")\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            pids = [id_num for cnt, url in enumerate(df[f\"{itype}_path\"]) if (id_num := executor.submit(req_image, url, save_path, df.iloc[cnt]['id']).result()) is not None]\n",
    "        problem_ids.extend(pids)\n",
    "        print(f\"{itype} images written successfully!\")\n",
    "    problem_ids = set(problem_ids)\n",
    "    df = df[~df['id'].isin(problem_ids)]\n",
    "    return df, problem_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, problem_ids = extract_images_threaded(df=df, cur_path=\".\", img_type=[\"poster\", \"backdrop\"], max_threads=2000)\n",
    "print(f\"Number of rows dropped due to missing images: {len(problem_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382c1f3",
   "metadata": {},
   "source": [
    "Additionally, we also feature engineer based on the release dates to split that column into year, month and day separately. This generally allows models to process such meta information better. We also bin the year and day as per the EDA; we will leave the months as it is as the values are generally small and in the range of the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb829706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def split_datetime(df: DataFrame,\n",
    "                   date_col: str) -> DataFrame:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format='%Y-%m-%d')\n",
    "    df[f\"{date_col}_year\"] = df[date_col].dt.year\n",
    "    df[f\"{date_col}_month\"] = df[date_col].dt.month\n",
    "    df[f\"{date_col}_day\"] = df[date_col].dt.day\n",
    "    df.drop(date_col, inplace=True, axis=1)\n",
    "    \n",
    "    day_bins = [0, 10, 20, 31]\n",
    "    day_labels = [1, 2, 3]\n",
    "    year_bins = [1900, 1940, 1960, 1980, 2000, 2020]\n",
    "    year_labels = [1, 2, 3, 4, 5]\n",
    "    df[f\"{date_col}_day\"]  = pd.cut(df[f\"{date_col}_day\"], bins=day_bins, labels=day_labels)\n",
    "    df[f\"{date_col}_year\"] = pd.cut(df[f\"{date_col}_year\"], bins=year_bins, labels=year_labels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5b43a",
   "metadata": {},
   "source": [
    "We also remove stopwords from the tagline and overview as they contribute a significant number of non-impactful words such as 'the' and 'a'. We remove the rows which have no taglines first to prevent us from running into string errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# remove stopwords & punctuation\n",
    "def remove_sw(df: DataFrame, sw: set, var: list, keep_missing: bool, save_path: str = \".\"):\n",
    "    if keep_missing:\n",
    "        unlabelled_df = df[(df[\"tagline\"] == '') | (df[\"tagline\"] == ' ')]\n",
    "        unlabelled_df.to_csv(os.path.join(save_path, \"tagless.csv\"))\n",
    "        print(f\"Tagless set size: {len(unlabelled_df)}\")\n",
    "        print(\"Tagless dataset created!\")\n",
    "    df = df[(df[\"tagline\"] != '') & (df[\"tagline\"] != ' ')]\n",
    "    df = df[df['tagline'].notna()]\n",
    "    for v in var:\n",
    "        df[v] = df[v].apply(lambda x: str.lower(x))\n",
    "        df[v] = df[v].apply(lambda x: \" \".join([word for word in word_tokenize(x) if word not in sw]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-server",
   "metadata": {},
   "source": [
    "Lastly, from the previous notebook on EDA, we have already identified the relevant and irrelevant features required for our tagline prediction task. We will now drop the columns or features that are irrelevant. We can also include the image url paths to be dropped as we have already extracted the necessary images into a separate folder.\n",
    "\n",
    "Speaking of dropped rows, let's also drop the rows which are missing information in the important columns identified during EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def drop_missing(df: DataFrame, cols: list) -> DataFrame:\n",
    "    df.dropna(subset=cols, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def drop_col(data: DataFrame,\n",
    "             irrelevant_cols: list,\n",
    "             relevant_cols: list,\n",
    "             sw: set,\n",
    "             var: list) -> DataFrame:\n",
    "    df = data.drop(irrelevant_cols, axis = 1)\n",
    "    df = drop_missing(df=df, cols=relevant_cols)\n",
    "    df = split_datetime(df=df, date_col=\"release_date\")\n",
    "    df = remove_sw(df=df, sw=sw, var=var, keep_missing=True)\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-title",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagless set size: 0\n",
      "Tagless dataset created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>Western</th>\n",
       "      <th>release_date_year</th>\n",
       "      <th>release_date_month</th>\n",
       "      <th>release_date_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>'s ted bellhop 's first night job ... hotel 's...</td>\n",
       "      <td>twelve outrageous guests four scandalous reque...</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>racing boxing match frank mike john rey get ba...</td>\n",
       "      <td>n't move n't whisper n't even breathe</td>\n",
       "      <td>Judgment Night</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>timo novotny labels new project experimental m...</td>\n",
       "      <td>megacities remix</td>\n",
       "      <td>Life in Loops (A Megacities RMX)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>princess leia captured held hostage evil imper...</td>\n",
       "      <td>long time ago galaxy far far away ...</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>nemo adventurous young clownfish unexpectedly ...</td>\n",
       "      <td>3.7 trillion fish ocean 're looking one</td>\n",
       "      <td>Finding Nemo</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           overview  \\\n",
       "2   5  's ted bellhop 's first night job ... hotel 's...   \n",
       "3   6  racing boxing match frank mike john rey get ba...   \n",
       "4   8  timo novotny labels new project experimental m...   \n",
       "6  11  princess leia captured held hostage evil imper...   \n",
       "7  12  nemo adventurous young clownfish unexpectedly ...   \n",
       "\n",
       "                                             tagline  \\\n",
       "2  twelve outrageous guests four scandalous reque...   \n",
       "3              n't move n't whisper n't even breathe   \n",
       "4                                   megacities remix   \n",
       "6              long time ago galaxy far far away ...   \n",
       "7            3.7 trillion fish ocean 're looking one   \n",
       "\n",
       "                              title  ...  Western  release_date_year  \\\n",
       "2                        Four Rooms  ...        0                  4   \n",
       "3                    Judgment Night  ...        0                  4   \n",
       "4  Life in Loops (A Megacities RMX)  ...        0                  5   \n",
       "6                         Star Wars  ...        0                  3   \n",
       "7                      Finding Nemo  ...        0                  5   \n",
       "\n",
       "   release_date_month  release_date_day  \n",
       "2                  12                 1  \n",
       "3                  10                 2  \n",
       "4                   1                 1  \n",
       "6                   5                 3  \n",
       "7                   5                 3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevant_columns = ['adult', 'belongs_to_collection','homepage','imdb_id','production_companies','popularity','original_language','original_title','revenue','runtime','spoken_languages','status','video','vote_average','vote_count','production_countries','budget', 'poster_path', 'backdrop_path']\n",
    "relevant_columns = list(set(df.columns) - set(irrelevant_columns))\n",
    "sw = set(stopwords.words('english') + list(string.punctuation))\n",
    "var = [\"overview\", \"tagline\"]\n",
    "df = drop_col(data=df, irrelevant_cols=irrelevant_columns, relevant_cols=relevant_columns, sw=sw, var=var)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-indonesian",
   "metadata": {},
   "source": [
    "Looking at the first 5 rows of the cleaned dataset, we easily see that some example taglines (under the tagline column) are missing. We'll need to separate these examples into a separate csv file as they do not have labels. Additionally, we can create our train, validation and test datasets concurrently and save them into separate csv files. This helps reproducibility later on. We also print the relative proportions of each dataset to see if we will need to redo the extraction process above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def create_splits(df: DataFrame,\n",
    "                  label: str,\n",
    "                  splits: list,\n",
    "                  seed: int,\n",
    "                  save_path: str = \".\"):\n",
    "\n",
    "    assert len(splits) == 2, \"Train, validation and test splits must be provided, please provide 2 of them as fractions.\"\n",
    "    df_size = len(df)\n",
    "    labelled_df = shuffle(df, random_state=seed)\n",
    "    labelled_df.reset_index(inplace=True, drop=True)\n",
    "    valid_start, test_start = int(df_size*splits[0]), int(df_size*splits[0] + df_size*splits[1])\n",
    "    train_df = labelled_df.iloc[:valid_start]\n",
    "    valid_df = labelled_df.iloc[valid_start:test_start]\n",
    "    test_df = labelled_df[test_start:]\n",
    "    print(f\"Train set size: {len(train_df)}\\nValid set size: {len(valid_df)}\\nTest set size: {len(test_df)}\")\n",
    "    train_df.to_csv(os.path.join(save_path, \"train.csv\"), index=False)\n",
    "    valid_df.to_csv(os.path.join(save_path, \"valid.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(save_path, \"test.csv\"), index=False)\n",
    "    print(\"Train, Validation and Test datasets created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2276\n",
      "Valid set size: 285\n",
      "Test set size: 285\n",
      "Train, Validation and Test datasets created!\n"
     ]
    }
   ],
   "source": [
    "splits = [0.8, 0.1]\n",
    "label = \"tagline\"\n",
    "seed = 42\n",
    "create_splits(df=df,\n",
    "              label=label,\n",
    "              splits=splits,\n",
    "              seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf9b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>Western</th>\n",
       "      <th>release_date_year</th>\n",
       "      <th>release_date_month</th>\n",
       "      <th>release_date_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4780</td>\n",
       "      <td>new orleans businessman michael courtland â€™ li...</td>\n",
       "      <td>bizarre story love</td>\n",
       "      <td>Obsession</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>543</td>\n",
       "      <td>london 1929. frank webber busy scotland yard d...</td>\n",
       "      <td>hold everything till 've heard one</td>\n",
       "      <td>Blackmail</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4257</td>\n",
       "      <td>cindy finds house lives haunted little boy goe...</td>\n",
       "      <td>bury grudge burn village see saw</td>\n",
       "      <td>Scary Movie 4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6020</td>\n",
       "      <td>falsely accused stealing budget annual cocktai...</td>\n",
       "      <td>way become one boys ... become one girls</td>\n",
       "      <td>Sorority Boys</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8740</td>\n",
       "      <td>rex saskia enjoying biking holiday france stop...</td>\n",
       "      <td>seen woman</td>\n",
       "      <td>The Vanishing</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           overview  \\\n",
       "0  4780  new orleans businessman michael courtland â€™ li...   \n",
       "1   543  london 1929. frank webber busy scotland yard d...   \n",
       "2  4257  cindy finds house lives haunted little boy goe...   \n",
       "3  6020  falsely accused stealing budget annual cocktai...   \n",
       "4  8740  rex saskia enjoying biking holiday france stop...   \n",
       "\n",
       "                                    tagline          title  ...  Western  \\\n",
       "0                        bizarre story love      Obsession  ...        0   \n",
       "1        hold everything till 've heard one      Blackmail  ...        0   \n",
       "2          bury grudge burn village see saw  Scary Movie 4  ...        0   \n",
       "3  way become one boys ... become one girls  Sorority Boys  ...        0   \n",
       "4                                seen woman  The Vanishing  ...        0   \n",
       "\n",
       "   release_date_year  release_date_month  release_date_day  \n",
       "0                  3                   8                 1  \n",
       "1                  1                   7                 3  \n",
       "2                  5                   4                 2  \n",
       "3                  5                   3                 3  \n",
       "4                  4                  10                 3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943c7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'overview', 'tagline', 'title', 'Action', 'Adventure',\n",
       "       'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family',\n",
       "       'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance',\n",
       "       'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western',\n",
       "       'release_date_year', 'release_date_month', 'release_date_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46684ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSAI-Project",
   "language": "python",
   "name": "dsai-project"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
