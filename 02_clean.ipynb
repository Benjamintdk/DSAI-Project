{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-aberdeen",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering\n",
    "> Cleaning and feature engineering based on the insights gained from the previous step on EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-inclusion",
   "metadata": {},
   "source": [
    "Looking at the first 5 rows of the scraped dataset, we easily see that some example taglines (under the tagline column) are missing. We'll need to separate these examples into a separate csv file as they do not have labels. Additionally, we can create our train, validation and test datasets concurrently and save them into separate csv files. This helps reproducibility later on. We also print the relative proportions of each dataset to see if we will need to redo the extraction process above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from pandas import DataFrame\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "import concurrent\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def create_splits(df: DataFrame,\n",
    "                  label: str,\n",
    "                  splits: list,\n",
    "                  seed: int,\n",
    "                  keep_missing: bool,\n",
    "                  save_path: str = \".\"):\n",
    "\n",
    "    assert len(splits) == 2, \"Train, validation and test splits must be provided, please provide 2 of them as fractions.\"\n",
    "    if keep_missing:\n",
    "        unlabelled_df = df[df[label] == '']\n",
    "        unlabelled_df.to_csv(os.path.join(save_path, \"tagless.csv\"))\n",
    "        print(f\"Tagless set size: {len(unlabelled_df)}\")\n",
    "        print(\"Tagless dataset created!\")\n",
    "    labelled_df = df[df[label] != '']\n",
    "    df_size = len(labelled_df)\n",
    "    labelled_df = shuffle(labelled_df, random_state=seed)\n",
    "    labelled_df.reset_index(drop=True, inplace=True)\n",
    "    valid_start, test_start = int(df_size*splits[0]), int(df_size*splits[0] + df_size*splits[1])\n",
    "    train_df = labelled_df.iloc[:valid_start]\n",
    "    valid_df = labelled_df.iloc[valid_start:test_start]\n",
    "    test_df = labelled_df[test_start:]\n",
    "    print(f\"Train set size: {len(train_df)}\\nValid set size: {len(valid_df)}\\nTest set size: {len(test_df)}\")\n",
    "    train_df.to_csv(os.path.join(save_path, \"train.csv\"))\n",
    "    valid_df.to_csv(os.path.join(save_path, \"valid.csv\"))\n",
    "    test_df.to_csv(os.path.join(save_path, \"test.csv\"))\n",
    "    print(\"Train, Validation and Test datasets created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [0.7, 0.15]\n",
    "label = \"tagline\"\n",
    "seed = 42\n",
    "# create_splits(df=movies,\n",
    "#               label=label,\n",
    "#               splits=splits,\n",
    "#               seed=seed,\n",
    "#               keep_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_col(data: DataFrame)->DataFrame:\n",
    "        \n",
    "        df = data.drop(['belongs_to_collection','homepage','imdb_id','production_companies','popularity','original_language','original_title','revenue','runtime','spoken_languages','status','video','vote_average','vote_count','production_countries','budget'],axis = 1)\n",
    "        df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d')\n",
    "        df =df.drop(df.columns[0], axis=1)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genre(df:DataFrame)-> DataFrame:\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    df['genres'] = [[x['name'] for x in eval(list_dict)] for list_dict in df['genres']]\n",
    "    df1 = df.join(\n",
    "                pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(df.pop('genres')),\n",
    "                index=df.index,\n",
    "                columns=mlb.classes_))\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_backdrop_img(df:DataFrame):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(\".\\\\backdrop_img\")\n",
    "    except FileExistsError:\n",
    "    # directory already exists\n",
    "        pass\n",
    "    \n",
    "    for cnt,x in enumerate(df['backdrop_path']):\n",
    "        \n",
    "        if x is not None:\n",
    "            response = requests.get(\"https://image.tmdb.org/t/p/original\"+str(x))\n",
    "            file = open(\".\\\\backdrop_img\\\\\"+str(df['id'][cnt])+\".jpg\", \"wb\")\n",
    "            file.write(response.content)\n",
    "            file.close()\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poster_img(df:DataFrame):\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(\".\\\\poster_img\")\n",
    "    except FileExistsError:\n",
    "    # directory already exists\n",
    "        pass\n",
    "    \n",
    "    for cnt,x in enumerate(df['poster_path']):\n",
    "        \n",
    "        if x is not None:\n",
    "            response = requests.get(\"https://image.tmdb.org/t/p/original\"+str(x))\n",
    "            file = open(\".\\\\poster_img\\\\\"+str(df['id'][cnt])+\".jpg\", \"wb\")\n",
    "            file.write(response.content)\n",
    "            file.close()\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
