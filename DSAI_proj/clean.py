# AUTOGENERATED! DO NOT EDIT! File to edit: 02_clean.ipynb (unless otherwise specified).

__all__ = ['clean_genre', 'extract_backdrop_img', 'extract_poster_img', 'drop_col', 'create_splits']

# Internal Cell
from pandas import DataFrame
from sklearn.utils import shuffle
from sklearn.preprocessing import MultiLabelBinarizer
from .extract import *
import os
import pandas as pd
import json
import concurrent
import requests
import pandas as pd
import numpy as np

# Cell

def clean_genre(df: DataFrame)-> DataFrame:

    mlb = MultiLabelBinarizer(sparse_output=True)
    df['genres'] = [[x['name'] for x in list_dict] for list_dict in df['genres']]
    df1 = df.join(
                pd.DataFrame.sparse.from_spmatrix(
                mlb.fit_transform(df.pop('genres')),
                index=df.index,
                columns=mlb.classes_))
    return df1

# Cell

def extract_backdrop_img(df: DataFrame, save_path: str):
    save_path = os.path.join(save_path, "backdrop_img")
    os.makedirs(save_path, exist_ok=True)

    for cnt,x in enumerate(df['backdrop_path']):

        if x is not None:
            response = requests.get("https://image.tmdb.org/t/p/original"+str(x))
            with open(os.path.join(save_path, str(df['id'][cnt])+".jpg"), "wb") as f:
                f.write(response.content)
    print("All backdrop images written successfully!")
    return

def extract_poster_img(df: DataFrame, save_path: str):
    save_path = os.path.join(save_path, "poster_img")
    os.makedirs(save_path, exist_ok=True)

    for cnt,x in enumerate(df['poster_path']):

        if x is not None:
            response = requests.get("https://image.tmdb.org/t/p/original"+str(x))
            with open(os.path.join(save_path, str(df['id'][cnt])+".jpg"), "wb") as f:
                f.write(response.content)
    print("All poster images written successfully!")
    return

# Cell

def drop_col(data: DataFrame,
             irrelevant_cols: list) -> DataFrame:
    df = data.drop(irrelevant_cols,axis = 1)
    df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d')
    df = df.drop(df.columns[0], axis=1)
    return df

# Cell

def create_splits(df: DataFrame,
                  label: str,
                  splits: list,
                  seed: int,
                  keep_missing: bool,
                  save_path: str = "."):

    assert len(splits) == 2, "Train, validation and test splits must be provided, please provide 2 of them as fractions."
    if keep_missing:
        unlabelled_df = df[df[label] == '']
        unlabelled_df.to_csv(os.path.join(save_path, "tagless.csv"))
        print(f"Tagless set size: {len(unlabelled_df)}")
        print("Tagless dataset created!")
    labelled_df = df[df[label] != '']
    df_size = len(labelled_df)
    labelled_df = shuffle(labelled_df, random_state=seed)
    valid_start, test_start = int(df_size*splits[0]), int(df_size*splits[0] + df_size*splits[1])
    train_df = labelled_df.iloc[:valid_start]
    valid_df = labelled_df.iloc[valid_start:test_start]
    test_df = labelled_df[test_start:]
    print(f"Train set size: {len(train_df)}\nValid set size: {len(valid_df)}\nTest set size: {len(test_df)}")
    train_df.to_csv(os.path.join(save_path, "train.csv"))
    valid_df.to_csv(os.path.join(save_path, "valid.csv"))
    test_df.to_csv(os.path.join(save_path, "test.csv"))
    print("Train, Validation and Test datasets created!")