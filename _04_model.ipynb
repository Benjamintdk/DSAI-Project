{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a9be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ca8eb",
   "metadata": {},
   "source": [
    "# Model\n",
    "> Our project will require the use of 4 separate types of models: an image model, a text model, a tabular model, and a decoder network. The relationship between the 4 can be seen in the figure below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecd15e",
   "metadata": {},
   "source": [
    "![](model_diagram.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730428ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "from fastai.data.core import DataLoaders\n",
    "from transformers import DistilBertModel\n",
    "from DSAI_proj.dataset import *\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def freeze_all_but_layer(m, layer):\n",
    "    if not isinstance(m, layer):\n",
    "        if hasattr(m, 'weight') and m.weight is not None:\n",
    "            m.weight.requires_grad_(False)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            m.bias.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61659c",
   "metadata": {},
   "source": [
    "We first design a cnn_encoder module using a pretrained resnet 18 architecture. We will keep the weights frozen as we do not want them to be updated too much in the training process. We also unfreeze the batchnorm layers, as these have been shown to learn the distributions better when unfrozen during fine-tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def cnn_encoder(pretrained: bool, in_channels: int, out_channels: int):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    last_layers = [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False), nn.AdaptiveAvgPool2d(1)]\n",
    "    model = nn.Sequential(*list(model.children())[:-2], *last_layers)\n",
    "    img_freeze_fn = partial(freeze_all_but_layer, layer=nn.BatchNorm2d)\n",
    "    model.apply(img_freeze_fn)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfdaec4",
   "metadata": {},
   "source": [
    "Next, we design a text_encoder module, which will consist of the encoder layers of DistilBert. Similar to the cnn_encoder, we freeze all the layers except the normalization layers, which in this case is LayerNorm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def text_encoder(model_type: str):\n",
    "    model = DistilBertModel.from_pretrained(model_type)\n",
    "    text_freeze_fn = partial(freeze_all_but_layer, layer=nn.LayerNorm) \n",
    "    model.apply(text_freeze_fn)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f3798",
   "metadata": {},
   "source": [
    "We will also need a module for our tabular meta data, and hence use a simple linear layer which will map the input meta data to necessary output shape required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def meta_encoder(in_channels: int, out_channels: int):\n",
    "    model = nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d4f7d",
   "metadata": {},
   "source": [
    "The last piece of the puzzle is a decoder network that will decode the outputs of the above 3 encoder modules and produce the predicted score where the last dimension represents the vocabulary size of the model. In other words, these are the raw logits distributed across all possible words, and a softmax will be applied to determine the most likely word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def decoder(hidden_dim: int, nhead: int, num_decoders: int, vocab_size: int):\n",
    "    decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=nhead)\n",
    "    transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoders)\n",
    "    linear_layer = nn.Linear(in_features=hidden_dim out_features=vocab_size)\n",
    "    model = nn.Sequential([transformer_decoder, linear_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e55dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaglinePredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, meta_features: int):\n",
    "        super(TaglinePredictorModel, self).__init__()\n",
    "        self.cnn_encoder = cnn_encoder(pretrained=True, in_channels=512, out_channels=768)\n",
    "        self.text_encoder = text_encoder(model_type='distilbert-base-uncased')\n",
    "        self.meta_encoder = meta_encoder(in_channels=meta_features, out_channels=768)\n",
    "        self.decoder = decoder(hidden_dim=768, nhead=12, num_decoders=3, vocab_size=30522)\n",
    "        \n",
    "    def forward(self, x: dict):\n",
    "        poster_feature = self.cnn_encoder(x['poster_img']).squeeze(-1).view(0, 2, 1)\n",
    "        backdrop_feature = self.cnn_encoder(x['backdrop_img']).squeeze(-1).view(0, 2, 1)\n",
    "        text_feature = self.text_encoder(x['text_inputs'])\n",
    "        meta_feature = self.meta_encoder(x['meta']).unsqueeze(1)\n",
    "        \n",
    "        hidden_dim = torch.cat((poster_feature, backdrop_feature, text_feature, meta_feature), dim=1)\n",
    "        for i in range()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079a9cf",
   "metadata": {},
   "source": [
    "The values for this Tagline model are mostly hard-coded as we are limited by architectural choices. As we will be using DistilBert, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c111f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSAI-Project",
   "language": "python",
   "name": "dsai-project"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
