---

title: Model


keywords: fastai
sidebar: home_sidebar

summary: "Our project will require the use of 4 separate types of models: an image model, a text model, a tabular model, and a decoder network. The relationship between the 4 can be seen in the figure below. "
description: "Our project will require the use of 4 separate types of models: an image model, a text model, a tabular model, and a decoder network. The relationship between the 4 can be seen in the figure below. "
nb_path: "04_model.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 04_model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/DSAI_proj/model_diagram.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We first design a cnn_encoder module using a pretrained resnet 18 architecture. We will keep the weights frozen as we do not want them to be updated too much in the training process. We also unfreeze the batchnorm layers, as these have been shown to learn the distributions better when unfrozen during fine-tuning.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="cnn_encoder" class="doc_header"><code>cnn_encoder</code><a href="https://github.com/Benjamintdk/DSAI_proj/tree/main/DSAI_proj/model.py#L27" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>cnn_encoder</code>(<strong><code>pretrained</code></strong>:<code>bool</code>, <strong><code>in_channels</code></strong>:<code>int</code>, <strong><code>out_channels</code></strong>:<code>int</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we design a text_encoder module, which will consist of the encoder layers of DistilBert. Similar to the cnn_encoder, we freeze all the layers except the normalization layers, which in this case is LayerNorm.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="text_encoder" class="doc_header"><code>text_encoder</code><a href="https://github.com/Benjamintdk/DSAI_proj/tree/main/DSAI_proj/model.py#L37" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>text_encoder</code>(<strong><code>model_type</code></strong>:<code>str</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will also need a module for our tabular meta data, and hence use a simple linear layer which will map the input meta data to necessary output shape required.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="meta_encoder" class="doc_header"><code>meta_encoder</code><a href="https://github.com/Benjamintdk/DSAI_proj/tree/main/DSAI_proj/model.py#L45" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>meta_encoder</code>(<strong><code>in_channels</code></strong>:<code>int</code>, <strong><code>out_channels</code></strong>:<code>int</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The last piece of the puzzle is a decoder network that will decode the outputs of the above 3 encoder modules and produce the predicted score where the last dimension represents the vocabulary size of the model. In other words, these are the raw logits distributed across all possible words, and a softmax will be applied to determine the most likely word. For our case, we will use a simple linear layer to act as the decoder layer.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="decoder" class="doc_header"><code>decoder</code><a href="https://github.com/Benjamintdk/DSAI_proj/tree/main/DSAI_proj/model.py#L52" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>decoder</code>(<strong><code>cur_len</code></strong>:<code>int</code>, <strong><code>max_seq_len</code></strong>:<code>int</code>, <strong><code>hidden_dim</code></strong>:<code>int</code>, <strong><code>vocab_size</code></strong>:<code>int</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TaglinePredictorModel" class="doc_header"><code>class</code> <code>TaglinePredictorModel</code><a href="https://github.com/Benjamintdk/DSAI_proj/tree/main/DSAI_proj/model.py#L62" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TaglinePredictorModel</code>(<strong><code>vocab_size</code></strong>:<code>int</code>, <strong><code>meta_features</code></strong>:<code>int</code>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The values for this Tagline model are mostly hard-coded as we are limited by architectural choices. As we will be using DistilBert for the text encoder, our hidden dimensions are limited to being 768, with a vocabulary size of 30522. Our choice of architecture for the image encoder is the resnet 18, which has a final output channel dimension of 512.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we are finally finished creating the model class, let's test it out on an example from the dataset created in the previous section. We'll additionally be testing out the FastAI dataloader as the model will be receiving the data directly from the dataloader during training and validation.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">DistilBertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">)</span>
<span class="n">input_max_length</span><span class="p">,</span> <span class="n">labels_max_length</span> <span class="o">=</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">height</span> <span class="o">=</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tfms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span><span class="n">Tokenize</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">input_max_length</span><span class="o">=</span><span class="n">input_max_length</span><span class="p">,</span> <span class="n">labels_max_length</span><span class="o">=</span><span class="n">labels_max_length</span><span class="p">),</span>
                         <span class="n">RandomResizeCrop</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">height</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">),</span>
                         <span class="n">ToTensor</span><span class="p">(),</span>
                         <span class="n">NormalizeStandardize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)])</span>

<span class="n">poster_img_dir</span> <span class="o">=</span> <span class="s2">&quot;poster_img/&quot;</span>
<span class="n">backdrop_img_dir</span> <span class="o">=</span> <span class="s2">&quot;backdrop_img/&quot;</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">MovieDataset</span><span class="p">(</span><span class="n">poster_img_dir</span><span class="o">=</span><span class="n">poster_img_dir</span><span class="p">,</span>
                        <span class="n">backdrop_img_dir</span><span class="o">=</span><span class="n">backdrop_img_dir</span><span class="p">,</span>
                        <span class="n">ds_type</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
                        <span class="n">transforms</span><span class="o">=</span><span class="n">tfms</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="o">.</span><span class="n">from_dsets</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TaglinePredictorModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">30522</span><span class="p">,</span> <span class="n">meta_features</span><span class="o">=</span><span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of output is </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>train dataset created!
Model is created!
Shape of output is torch.Size([1, 10, 30522])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

